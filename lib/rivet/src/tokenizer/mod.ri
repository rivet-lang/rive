// Copyright (C) 2023 The Rivet Developers. All rights reserved.
// Use of this source code is governed by an MIT license that can
// be found in the LICENSE file.

import std/strconv;
import std/strings;
import std/process;

import ../ast;
import ../token;
import ../prefs;
import ../utils;
import ../report;

import { LF, CR } from ../utils;

const NUM_SEP = b'_';

[boxed]
public struct Tokenizer {
    table: ast.Table;
    prefs: prefs.Prefs;
    file: string = "<internal-memory>";
    text: string;
    mut pos: usize;
    mut line: usize;
    mut last_nl_pos: usize;
    public mut all_tokens: []token.Token;
    mut tidx: usize;
    mut is_started: bool;
    mut is_cr_lf: bool;
    mut eofs: usize;
    mut conditional_stack: []Conditional;

    public func new(text: string, prefs: prefs.Prefs, table: ast.Table) Tokenizer {
        mut t := Tokenizer(table: table, prefs: prefs, text: text);
        t.init();
        return t;
    }

    public func from_file(file: string, prefs: prefs.Prefs, table: ast.Table) Tokenizer {
        mut t := Tokenizer(
            table: table, prefs: prefs, file: file,
            text: utils.read_file(file) catch |err| utils.error(err.to_string())
        );
        t.init();
        return t;
    }

    func init(mut self) {
        self.all_tokens = @vec(token.Token, self.text.len / 3);
        self.tokenize_remaining_text();
    }

    func tokenize_remaining_text(mut self) {
        while {
            t := self.internal_next();
            self.all_tokens.push(t);
            if t.kind == .EndOfFile {
                break;
            }
        }
    }

    [inline]
    func new_token(self, kind: token.Kind, lit: string = "", len: usize = 1) token.Token {
        return token.Token(lit, kind, len, token.Pos(
            file: self.file,
            line: self.line,
            col: utils.max(1, self.current_column() - len + 1) - 1,
            pos: self.pos - len + 1,
            len: len
        ));
    }

    [inline]
    func new_multiline_token(
        self, kind: token.Kind, lit: string = "", len: usize = 1,
        start_line: usize = 0, end_line: usize = 0, start_col: usize = 0
    ) token.Token {
        return token.Token(lit, kind, len, token.Pos(
            file: self.file,
            line: start_line,
            end_line: end_line,
            col: start_col,
            end_col: utils.max(1, self.current_column() + 1) - 2,
            pos: self.pos - len + 1,
            len: len,
            is_multiline: true
        ));
    }

    [inline]
    func new_eof_token(self) token.Token {
        return token.Token(
            kind: .EndOfFile,
            pos: token.Pos(
                file: self.file,
                line: self.line - 1,
                col: self.current_column() - 1,
                pos: self.pos,
                len: 1
            )
        );
    }

    func end_of_file(mut self) token.Token {
        self.eofs += 1;
        if self.eofs > 50 {
            self.line -= 1;
            process.panic("the end of file `{}` has been reached 50 times already".fmt(self.file));
        }
        if self.pos != self.text.len and self.eofs == 1 {
            self.inc_line_number();
        }
        self.pos = self.text.len;
        return self.new_eof_token();
    }

    [inline]
    func current_char(self) uint8 {
        return self.text[self.pos];
    }

    [inline]
    func current_pos(self) token.Pos {
        return token.Pos(
            file: self.file,
            line: self.line,
            col: self.current_column(),
            pos: self.pos,
            len: 1
        );
    }

    [inline]
    func current_column(self) usize {
        return if self.line == 0 {
            self.pos + 1
        } else {
            self.pos - self.last_nl_pos
        };
    }

    func ignore_line(mut self) {
        self.eat_to_end_of_line();
        self.inc_line_number();
    }

    [inline]
    func eat_to_end_of_line(mut self) {
        while self.pos < self.text.len and self.current_char() != LF : self.pos += 1 {}
    }

    func inc_line_number(mut self) {
        self.last_nl_pos = utils.min(self.text.len - 1, self.pos);
        if self.is_cr_lf {
            self.last_nl_pos += 1;
        }
        self.line += 1;
    }

    [inline]
    func skip_whitespace(mut self) {
        while self.pos < self.text.len : self.pos += 1 {
            c := self.current_char();
            if c == 8 {
                self.pos += 1;
                continue;
            }
            if !(c == 32 or (c > 8 and c < 14) or (c == 0x85) or (c == 0xA0)) {
                return;
            }
            if c == CR and self.look_ahead(1) == LF {
                self.is_cr_lf = true;
            }
            // count `\r\n` as one line
            if utils.is_new_line(c) and !(self.text[self.pos - 1] == CR and c == LF) {
                self.inc_line_number();
            }
        }
    }

    func matches(self, want: string, start_pos: usize) bool {
        end_pos := start_pos + want.len;
        if start_pos < 0 or end_pos < 0 or start_pos >= self.text.len
            or end_pos > self.text.len {
            return false;
        }
        mut pos: usize := start_pos;
        while pos < end_pos : pos += 1 {
            if self.text[pos] != want[pos - start_pos] {
                return false;
            }
        }
        return true;
    }

    [inline]
    public func peek_token(self, n: usize) token.Token {
        idx := self.tidx + n;
        return if idx >= self.all_tokens.len {
            self.new_eof_token()
        } else {
            self.all_tokens[idx]
        };
    }

    [inline]
    func look_ahead(self, n: usize) uint8 {
        return if self.pos + n < self.text.len {
            self.text[self.pos + n]
        } else {
            0
        };
    }

    func trim_slash_line_break(self, s: string) string {
        (mut start: usize, mut ret_str) := (0, s);
        while idx := ret_str.index_after_of("\\\n", start) {
            ret_str = ret_str[..idx].concat(ret_str[idx + 2..].trim_left(" \n\t\v\f\r"));
            start = idx;
        }
        return ret_str;
    }

    [inline]
    func number_literal_without_separator(self, lit: string) string {
        return if lit.contains("_") {
            mut sb := strings.Builder.new(lit.len - lit.count("_"));
            for ch in lit.as_bytes() {
                if ch != b'_' {
                    sb.write_byte(ch);
                }
            }
            sb.to_string()
        } else {
            lit
        };
    }

    func invalid_character(mut self) {
        len := self.text[self.pos].len_utf8();
        end := utils.min(self.pos + len, self.text.len);
        self.error("invalid character: `{}`".fmt(self.text[self.pos..end]));
        self.pos += len;
    }

    [inline]
    func error(self, msg: string, pos: token.Pos = self.current_pos()) {
        report.error(msg, pos);
    }

    [inline]
    func warn(self, msg: string, pos: token.Pos = self.current_pos()) {
        report.warn(msg, pos);
    }

    [inline]
    func error_builder(self, msg: string, pos: token.Pos = self.current_pos()) report.ReportBuilder {
        return report.error_builder(msg, pos);
    }

    [inline]
    func warn_builder(self, msg: string, pos: token.Pos = self.current_pos()) report.ReportBuilder {
        return report.warn_builder(msg, pos);
    }
}

// NOTE: this function doesn't do any decoding... it just replaces '\xc0' with
// the byte 0xc0
func decode_h_escape_single(str: string, idx: usize) (usize, string) {
    end_idx := idx + 4; // "\xXX".len == 4
    return (
        end_idx,
        @cast(uint8, strconv.parse_uint(str[idx + 2..end_idx], 16, 8) catch 0).to_string()
    );
}

// only handle single-byte inline escapes like '\xc0'
func decode_h_escapes(s: string, start: usize, escapes_pos: []usize) string {
    if escapes_pos.is_empty() {
        return s;
    }
    mut ss := @vec(string, escapes_pos.len * 2 + 1);
    ss.push(s[..escapes_pos[escapes_pos.len - 1] - start]);
    for i, pos in escapes_pos {
        idx := pos - start;
        (end_idx, segment) := decode_h_escape_single(s, idx);
        ss.push(segment);
        ss.push(if i + 1 < escapes_pos.len {
            s[end_idx..escapes_pos[i + 1] - start]
        } else {
            s[end_idx..]
        });
    }
    return utils.join(ss, "");
}

// handle single-byte inline octal escapes like '\###'
// NOTE: this function doesn't do any decoding... it just replaces '\141' with
// the byte 0o141
func decode_o_escapes(s: string, start: usize, escapes_pos: []usize) string {
    if escapes_pos.is_empty() {
        return s;
    }
    mut ss := @vec(string, escapes_pos.len);
    // everything before the first escape code position
    ss.push(s[..escapes_pos[escapes_pos.len - 1] - start]);
    for i, pos in escapes_pos {
        idx := pos - start;
        end_idx := idx + 4; // "\XXX".len == 4
        ss.push(
            @cast(uint8, strconv.parse_uint(s[idx + 1..end_idx], 8, 8) catch 0).to_string()
        );
        ss.push(if i + 1 < escapes_pos.len {
            s[end_idx..escapes_pos[i + 1] - start]
        } else {
            s[end_idx..]
        });
    }
    return utils.join(ss, "");
}

func decode_u_escape_single(str: string, idx: usize) (usize, string) {
    end_idx := idx + 6; // "\uXXXX".len == 6
    escaped_code_point := strconv.parse_uint(str[idx + 2..end_idx], 16, 32) catch 0;
    return (end_idx, @cast(uint32, escaped_code_point).to_string());
}

// decode the flagged unicode escape sequences into their utf-8 bytes
func decode_u_escapes(str: string, start: usize, escapes_pos: []usize) string {
    if escapes_pos.is_empty() {
        return str;
    }
    mut ss := @vec(string, escapes_pos.len * 2 + 1);
    ss.push(str[..escapes_pos[escapes_pos.len - 1] - start]);
    for i, pos in escapes_pos {
        idx := pos - start;
        (end_idx, segment) := decode_u_escape_single(str, idx);
        ss.push(segment);
        ss.push(if i + 1 < escapes_pos.len {
            str[end_idx..escapes_pos[i + 1] - start]
        } else {
            str[end_idx..]
        });
    }
    return utils.join(ss, "");
}
